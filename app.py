import streamlit as st
import pandas as pd
import datetime
import time
import requests
import io
import base64  # <--- Î— Î±Ï€Î±ÏÎ±Î¯Ï„Î·Ï„Î· Ï€ÏÎ¿ÏƒÎ¸Î®ÎºÎ· Î³Î¹Î± Ï„Î¿ AutoPlay
from openai import OpenAI
from streamlit_mic_recorder import mic_recorder

# --- 1. Î¡Î¥Î˜ÎœÎ™Î£Î•Î™Î£ Î£Î•Î›Î™Î”Î‘Î£ & CONFIGURATION ---
st.set_page_config(
    page_title="Creta Gas AI Knowledge Hub", 
    page_icon="ğŸ”¥", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- 2. SECURITY & API HANDLING (GITHUB SAFE) ---
# ÎŸ ÎºÏÎ´Î¹ÎºÎ±Ï‚ ÏˆÎ¬Ï‡Î½ÎµÎ¹ Ï„Î± ÎºÎ»ÎµÎ¹Î´Î¹Î¬ ÏƒÏ„Î± "Secrets" Ï„Î¿Ï… Cloud.
if "OPENAI_API_KEY" in st.secrets and "ELEVENLABS_API_KEY" in st.secrets:
    openai_api_key = st.secrets["OPENAI_API_KEY"]
    elevenlabs_api_key = st.secrets["ELEVENLABS_API_KEY"]
else:
    # Î‘Î½ Ï„ÏÎ­Ï‡ÎµÎ¹ ÎºÎ±Î¹ Î´ÎµÎ½ Î²ÏÎ¯ÏƒÎºÎµÎ¹ ÎºÎ»ÎµÎ¹Î´Î¹Î¬
    st.error("âš ï¸ SYSTEM HALT: Missing API Keys in Streamlit Secrets.")
    st.info("Î Î±ÏÎ±ÎºÎ±Î»Ï Ï€Î·Î³Î±Î¯Î½ÎµÏ„Îµ: Settings -> Secrets ÎºÎ±Î¹ Ï€ÏÎ¿ÏƒÎ¸Î­ÏƒÏ„Îµ Ï„Î± OPENAI_API_KEY & ELEVENLABS_API_KEY")
    st.stop()

# Î£ÏÎ½Î´ÎµÏƒÎ· Î¼Îµ Ï„Î¿ "ÎœÏ…Î±Î»ÏŒ" (OpenAI)
try:
    client = OpenAI(api_key=openai_api_key)
except Exception as e:
    st.error(f"âŒ Critical Connection Error: {e}")
    st.stop()

# --- 3. DATA LAYER (MOCK DATABASE) ---
def create_mock_database():
    # Î ÏÎ¿ÏƒÎ¿Î¼Î¿Î¯Ï‰ÏƒÎ· Î²Î¬ÏƒÎ·Ï‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ SoftOne (ERP)
    data_softone = {
        "id": [101, 102, 103, 104, 105],
        "name": ["Î¤Î±Î²Î­ÏÎ½Î± 'ÎŸ ÎÎ¯ÎºÎ¿Ï‚'", "Blue Coast Hotel & Resort", "Î Î»Î±ÏƒÏ„Î¹ÎºÎ¬ ÎšÏÎ®Ï„Î·Ï‚ Î‘Î’Î•Î•", "Super Market Î‘Î¦ÎŸÎ™", "Cafe Î‘Î¼Î¬Î½"],
        "balance": [450.50, 12500.00, 5000.00, 0.00, 120.00],
        "currency": ["EUR", "EUR", "EUR", "EUR", "EUR"],
        "status": ["Overdue", "Active", "Active", "Active", "Overdue"],
        "last_payment": ["2023-10-01", "2023-11-15", "2023-11-20", "2023-11-22", "2023-09-10"]
    }
    
    # Î ÏÎ¿ÏƒÎ¿Î¼Î¿Î¯Ï‰ÏƒÎ· CRM / Î£Ï…Î¼Ï†Ï‰Î½Î¹ÏÎ½
    data_agreements = {
        "customer_id": [101, 102, 103, 104, 105],
        "agreement_note": [
            "âš ï¸ Î Î¡ÎŸÎ£ÎŸÎ§Î—: ÎœÏŒÎ½Î¿ Î¼ÎµÏ„ÏÎ·Ï„Î¿Î¯Ï‚ (Blacklist Candidate)", 
            "ğŸ’ VIP Î£Ï…Î¼Ï†Ï‰Î½Î¯Î±: 5% ÎˆÎºÏ€Ï„Ï‰ÏƒÎ· Î»ÏŒÎ³Ï‰ Î³Î½Ï‰ÏÎ¹Î¼Î¯Î±Ï‚ CEO", 
            "ğŸ­ Î£Ï…Î¼Î²ÏŒÎ»Î±Î¹Î¿ Î’Î¹Î¿Î¼Î·Ï‡Î±Î½Î¹ÎºÎ¿Ï - Î¤Î¹Î¼Î® Î–ÏÎ½Î·Ï‚ Î’", 
            "ğŸ†• ÎÎ­Î¿Ï‚ Ï€ÎµÎ»Î¬Ï„Î·Ï‚ - Î¥Ï€ÏŒ Î´Î¿ÎºÎ¹Î¼Î®", 
            "ğŸ“„ Î Î±Î»Î¹Î¬ ÏƒÏ…Î¼Ï†Ï‰Î½Î¯Î± - Î§Ï‰ÏÎ¯Ï‚ Î­ÎºÏ€Ï„Ï‰ÏƒÎ·"
        ],
        "logistics_note": [
            "ğŸš› Î•Î¯ÏƒÎ¿Î´Î¿Ï‚ Î±Ï€ÏŒ Ï€Î¯ÏƒÏ‰ Ï€ÏŒÏÏ„Î± ÎºÎ¿Ï…Î¶Î¯Î½Î±Ï‚", 
            "â° Î Î±ÏÎ¬Î´Î¿ÏƒÎ· 08:00-10:00 Î±Ï…ÏƒÏ„Î·ÏÎ¬", 
            "ğŸšœ Î§ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹ ÎºÎ»Î±ÏÎº - Î ÏÎ¿Ï„ÎµÏÎ±Î¹ÏŒÏ„Î·Ï„Î± 4Ï‰ÏÎ¿Ï…", 
            "âœ… Î•ÏÎºÎ¿Î»Î· Ï€ÏÏŒÏƒÎ²Î±ÏƒÎ· - Î¡Î¬Î¼Ï€Î±", 
            "âš ï¸ Î£Ï„ÎµÎ½ÏŒ Î´ÏÎ¿Î¼Î¬ÎºÎ¹ - ÎœÏŒÎ½Î¿ Î¼Î¹ÎºÏÏŒ Ï†Î¿ÏÏ„Î·Î³ÏŒ (Van)"
        ],
        "contact_person": ["ÎšÎ¿Ï‚ ÎÎ¯ÎºÎ¿Ï‚", "ÎºÎ± ÎœÎ±ÏÎ¯Î± (Î›Î¿Î³Î¹ÏƒÏ„Î®ÏÎ¹Î¿)", "ÎšÎ¿Ï‚ Î“Î¹ÏÏÎ³Î¿Ï‚ (Î‘Ï€Î¿Î¸Î®ÎºÎ·)", "ÎšÎ¿Ï‚ Î“Î¹Î¬Î½Î½Î·Ï‚", "ÎšÎ¿Ï‚ Î£Ï„ÏÎ¬Ï„Î¿Ï‚"]
    }

    df1 = pd.DataFrame(data_softone)
    df2 = pd.DataFrame(data_agreements)
    # Join tables (ERP + CRM)
    return pd.merge(df1, df2, left_on="id", right_on="customer_id", how="left")

full_data = create_mock_database()

# --- 4. EXTRAS: AUTOPLAY AUDIO FUNCTION (NEW FEATURE) ---
# Î‘Ï…Ï„Î® Î· ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· ÎµÏ€Î¹Ï„ÏÎ­Ï€ÎµÎ¹ ÏƒÏ„Î¿Î½ Î®Ï‡Î¿ Î½Î± Ï€Î±Î¯Î¶ÎµÎ¹ Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î± Ï‡Ï‰ÏÎ¯Ï‚ ÎºÎ»Î¹Îº
def autoplay_audio(audio_content):
    # ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® Ï„Ï‰Î½ bytes ÏƒÎµ base64 string
    b64 = base64.b64encode(audio_content).decode()
    # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± ÎºÏÏ…Ï†Î¿Ï HTML player Ï€Î¿Ï… ÎºÎ¬Î½ÎµÎ¹ autoplay
    md = f"""
        <audio controls autoplay>
        <source src="data:audio/mp3;base64,{b64}" type="audio/mp3">
        </audio>
        """
    st.markdown(md, unsafe_allow_html=True)

# --- 5. UI SIDEBAR & SECURITY LAYER ---
st.title("ğŸ”¥ Creta Gas: Enterprise AI Hub")
st.markdown("### *Unified Intelligence: ERP + CRM + ElevenLabs Voice*")
st.markdown("---")

with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/2103/2103633.png", width=80)
    st.header("âš™ï¸ Control Center")
    st.divider()
    
    # User Access Control
    st.subheader("ğŸ‘¤ Identity Management")
    user_role = st.selectbox(
        "Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Î¡ÏŒÎ»Î¿ Î§ÏÎ®ÏƒÏ„Î·:", 
        ["CEO (God Mode)", "Sales Manager", "Driver (Field Ops)"]
    )
    
    # Visual Feedback Î³Î¹Î± Ï„Î¿Î½ ÏÏŒÎ»Î¿
    if "CEO" in user_role:
        st.success("ğŸŸ¢ Full Access Granted")
    elif "Sales" in user_role:
        st.info("ğŸ”µ Sales Access Granted")
    else:
        st.error("ğŸ”´ Driver Access (Restricted)")

    st.divider()

    # --- Î¡Î¥Î˜ÎœÎ™Î£Î•Î™Î£ Î¦Î©ÎÎ—Î£ (ELEVENLABS) ---
    st.subheader("ğŸ”Š Audio Configuration")
    
    # Î›Î¯ÏƒÏ„Î± Î¼Îµ IDs Ï„Î·Ï‚ ElevenLabs
    voice_options = {
        "Rachel (Î‘Î¼ÎµÏÎ¹ÎºÎ¬Î½Î¹ÎºÎ·/ÎšÎ±Î¸Î±ÏÎ®)": "21m00Tcm4TlvDq8ikWAM",
        "Charlie (Î‘Î½Ï„ÏÎ¹ÎºÎ®/Î‰ÏÎµÎ¼Î·)": "IKne3meq5aSn9XLyUdCD",
        "Nicole (Î•Ï€Î±Î³Î³ÎµÎ»Î¼Î±Ï„Î¹ÎºÎ®)": "piTKgcLEGmPE4e6mEKli",
        "Mimi (Î Î±Î¹Î´Î¹ÎºÎ®)": "zrHiDhphv9ZnVXBqCLjf"
    }
    
    selected_voice_name = st.selectbox("Î•Ï€Î¹Î»Î¿Î³Î® Î¦Ï‰Î½Î®Ï‚ AI:", list(voice_options.keys()))
    selected_voice_id = voice_options[selected_voice_name]
    
    st.caption(f"Voice Engine: ElevenLabs Multilingual v2\nID: {selected_voice_id}")


# --- 6. CORE AI ENGINE ---

# (Î‘) Whisper (Speech to Text)
def transcribe_audio_whisper(audio_bytes):
    try:
        audio_file = io.BytesIO(audio_bytes)
        audio_file.name = "voice_input.wav" 
        transcript = client.audio.transcriptions.create(
            model="whisper-1", 
            file=audio_file,
            language="el"
        )
        return transcript.text
    except Exception as e:
        return f"Audio Error: {e}"

# (Î’) ElevenLabs (Text to Speech)
def generate_elevenlabs_audio(text, api_key, voice_id):
    url = f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}"
    headers = {
        "Accept": "audio/mpeg",
        "Content-Type": "application/json",
        "xi-api-key": api_key
    }
    data = {
        "text": text,
        "model_id": "eleven_multilingual_v2", 
        "voice_settings": {
            "stability": 0.5,
            "similarity_boost": 0.75
        }
    }
    try:
        response = requests.post(url, json=data, headers=headers)
        if response.status_code == 200:
            return response.content
        else:
            # Î•Ï€Î¹ÏƒÏ„ÏÎ¿Ï†Î® Î»Î¬Î¸Î¿Ï…Ï‚ Î³Î¹Î± Debugging
            st.error(f"ElevenLabs Error: {response.text}")
            return None
    except Exception as e:
        st.error(f"Connection Error: {e}")
        return None

# (Î“) GPT-4o Logic (The Brain)
def get_smart_response(user_query, context_data, role):
    # Dynamic Security Protocol
    if "Driver" in role:
        security_protocol = "SECURITY: Do NOT reveal money/balances. Focus on Logistics/Location only."
    elif "Sales" in role:
        security_protocol = "SECURITY: Reveal balances. Focus on Sales/Negotiation."
    else:
        security_protocol = "SECURITY: Full Access. No restrictions."

    system_message = f"""
    ROLE: You are the advanced AI Assistant of Creta Gas.
    CONTEXT DATA: {context_data.to_string()}
    SECURITY: {security_protocol}
    INSTRUCTIONS:
    1. Language: Greek (Î•Î»Î»Î·Î½Î¹ÎºÎ¬).
    2. Tone: Professional but natural.
    3. Length: Short and concise (Max 2 sentences).
    """
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_message},
                {"role": "user", "content": user_query}
            ],
            temperature=0.3
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"System Error: {str(e)}"

# --- 7. INTERFACE & INTERACTION ---

if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- INPUT SECTION ---
st.markdown("### ğŸ™ï¸ Voice Command Center")

col_mic, col_text = st.columns([1, 4])
prompt = None

with col_mic:
    # ÎšÎ±Ï„Î±Î³ÏÎ±Ï†Î® Î®Ï‡Î¿Ï…
    audio_data = mic_recorder(
        start_prompt="ğŸ¤ PUSH TO TALK",
        stop_prompt="â¹ï¸ RELEASE", 
        key='recorder',
        just_once=True,
        use_container_width=True
    )

with col_text:
    text_input = st.chat_input("Type your query or use voice above...")

if audio_data:
    with st.spinner("ğŸ§ Processing Audio Stream..."):
        prompt = transcribe_audio_whisper(audio_data['bytes'])
elif text_input:
    prompt = text_input

# --- EXECUTION LOOP ---
if prompt:
    # 1. Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· ÎµÏÏÏ„Î·ÏƒÎ·Ï‚ Ï‡ÏÎ®ÏƒÏ„Î·
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # 2. Î£ÎºÎ­ÏˆÎ· AI & Latency Check
    start_time = time.time()
    with st.spinner('ğŸ§  Analyzing Data & Security Protocols...'):
        response_text = get_smart_response(prompt, full_data, user_role)
    end_time = time.time()
    latency = round(end_time - start_time, 2)

    # 3. Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· Î±Ï€Î¬Î½Ï„Î·ÏƒÎ·Ï‚ & Î‰Ï‡Î¿Ï‚
    with st.chat_message("assistant"):
        st.markdown(response_text)
        
        # --- ElevenLabs Generation DISABLED (COMMENTED OUT) ---
        # with st.spinner(f"ğŸ”Š Synthesizing Voice ({selected_voice_name})..."):
        #     audio_bytes = generate_elevenlabs_audio(response_text, elevenlabs_api_key, selected_voice_id)
        #     
        #     if audio_bytes:
        #         # Î§Î¡Î—Î£Î— Î¤Î—Î£ ÎÎ•Î‘Î£ Î›Î•Î™Î¤ÎŸÎ¥Î¡Î“Î™Î‘Î£ AUTOPLAY
        #         autoplay_audio(audio_bytes)
        #     else:
        #         st.warning("âš ï¸ Voice Generation Failed (Check Logs).")
        
        # --- LOGS & DEBUGGING (COMPLETE ENTERPRISE VIEW) ---
        with st.expander("ğŸ› ï¸ System Logs (Debug Info)"):
            st.code(f"""
            [INFO] Timestamp: {datetime.datetime.now()}
            [INFO] User Role: {user_role}
            [INFO] Latency: {latency}s
            [VOICE] Provider: ElevenLabs (DISABLED)
            [VOICE] Model: eleven_multilingual_v2
            [VOICE] ID: {selected_voice_id}
            """, language="yaml")

    st.session_state.messages.append({"role": "assistant", "content": response_text})

# --- Î¤ÎŸ DATA LAKE ---
st.markdown("---")
with st.expander("ğŸ“‚ View Raw Data Lake (Database Inspection)"):
    st.dataframe(full_data)